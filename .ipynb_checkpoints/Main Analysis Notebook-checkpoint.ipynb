{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "We are attempting use the Data Science Methods to find Video Game Trends over the last 30 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 Linear Regression and Time Series Analysis on Sales (ARIMA and Simple Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from pyspark.sql import SQLContext, SparkSession, Row, functions as fn\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover,CountVectorizer, IDF\n",
    "from pyspark.ml import feature, clustering, Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read only cell\n",
    "\n",
    "import os\n",
    "\n",
    "# get the databricks runtime version\n",
    "db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n",
    "\n",
    "# Define a function to read the data file.  The full path data file name is constructed\n",
    "# by checking runtime environment variables to determine if the runtime environment is \n",
    "# databricks, or a student's personal computer.  The full path file name is then\n",
    "# constructed based on the runtime env.\n",
    "# \n",
    "# Params\n",
    "#   data_file_name: The base name of the data file to load\n",
    "# \n",
    "# Returns the full path file name based on the runtime env\n",
    "#\n",
    "def get_training_filename(data_file_name):    \n",
    "    # if the databricks env var exists\n",
    "    if db_env != None:\n",
    "        # build the full path file name assuming data brick env\n",
    "        full_path_name = \"/FileStore/tables/%s\" % data_file_name\n",
    "    # else the data is assumed to be in the same dir as this notebook\n",
    "    else:\n",
    "        # Assume the student is running on their own computer and load the data\n",
    "        # file from the same dir as this notebook\n",
    "        full_path_name = data_file_name\n",
    "    \n",
    "    # return the full path file name to the caller\n",
    "    return full_path_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 Clustering Analysis (Kmeans and PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for Plots and datatypes cast\n",
    "from pyspark.sql.types import DoubleType, DecimalType\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler,Normalizer\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pyspark.ml import feature, Pipeline, PipelineModel\n",
    "from pyspark.sql.functions import col,sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
